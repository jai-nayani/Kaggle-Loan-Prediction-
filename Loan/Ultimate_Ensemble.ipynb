{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ultimate Ensemble Solution\n",
        "\n",
        "**Combines the best of all approaches:**\n",
        "1. Conservative feature engineering (target encoding, frequency encoding, binning)\n",
        "2. Ultimate advanced features (residual boosting, interactions, risk flags)\n",
        "3. Multi-model ensemble (XGB, LGB, CatBoost with diverse configs)\n",
        "4. Pseudo-labeling for data augmentation\n",
        "5. Advanced blending (power averaging, rank averaging, optimized weights)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set all random seeds\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
        "\n",
        "# Kaggle paths\n",
        "BASE_PATH = Path('/kaggle/input/playground-series-s5e11')\n",
        "ORIG_PATH = Path('/kaggle/input/loan-dataset-20000/loan_dataset_20000.csv')\n",
        "OUTPUT_PATH = Path('/kaggle/working/submission_ultimate_ensemble.csv')\n",
        "PRED_DUMP = Path('/kaggle/working/all_predictions.csv')\n",
        "\n",
        "# For local testing\n",
        "# BASE_PATH = Path('Loan')\n",
        "# ORIG_PATH = Path('loan_dataset_20000.csv')\n",
        "# OUTPUT_PATH = Path('Loan/submission_ultimate_ensemble.csv')\n",
        "\n",
        "target = 'loan_paid_back'\n",
        "N_FOLDS = 10\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ULTIMATE ENSEMBLE SOLUTION (Target: 0.928+)\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "print(\"Loading data...\")\n",
        "train = pd.read_csv(BASE_PATH / 'train.csv')\n",
        "test = pd.read_csv(BASE_PATH / 'test.csv')\n",
        "\n",
        "# Try multiple possible paths for original dataset\n",
        "original = None\n",
        "has_original = False\n",
        "possible_paths = [\n",
        "    Path('/kaggle/input/loan-dataset-20000/loan_dataset_20000.csv'),\n",
        "    Path('/kaggle/input/loan-dataset-20000-csv/loan_dataset_20000.csv'),\n",
        "    Path('/kaggle/input/loan-dataset-20000-csv/loan_dataset_20000.csv'),\n",
        "    Path('/kaggle/input/loan-dataset-20000-csv'),\n",
        "    Path('/kaggle/input/loan-dataset-20000'),\n",
        "]\n",
        "\n",
        "# Also check if there's a CSV file directly in the input folder\n",
        "import os\n",
        "for path in possible_paths:\n",
        "    if path.exists():\n",
        "        if path.is_file():\n",
        "            original = pd.read_csv(path)\n",
        "            has_original = True\n",
        "            print(f\"âœ“ Original dataset loaded from: {path}\")\n",
        "            print(f\"  Shape: {original.shape}\")\n",
        "            break\n",
        "        elif path.is_dir():\n",
        "            # Look for CSV files in the directory\n",
        "            csv_files = list(path.glob('*.csv'))\n",
        "            if csv_files:\n",
        "                original = pd.read_csv(csv_files[0])\n",
        "                has_original = True\n",
        "                print(f\"âœ“ Original dataset loaded from: {csv_files[0]}\")\n",
        "                print(f\"  Shape: {original.shape}\")\n",
        "                break\n",
        "\n",
        "if not has_original:\n",
        "    print(\"âš  Original dataset not found, skipping residual boosting\")\n",
        "    print(\"  Tried paths:\")\n",
        "    for path in possible_paths:\n",
        "        print(f\"    - {path} (exists: {path.exists()})\")\n",
        "    print(\"\\n  To find the correct path, run:\")\n",
        "    print(\"    import os\")\n",
        "    print(\"    print([d for d in os.listdir('/kaggle/input')])\")\n",
        "\n",
        "submission = pd.read_csv(BASE_PATH / 'sample_submission.csv')\n",
        "print(f\"\\nTrain: {train.shape}, Test: {test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_grade_mapping() -> Dict[str, int]:\n",
        "    grades = []\n",
        "    for letter in ['A', 'B', 'C', 'D', 'E', 'F', 'G']:\n",
        "        for num in range(1, 6):\n",
        "            grades.append(f\"{letter}{num}\")\n",
        "    return {g: i for i, g in enumerate(grades)}\n",
        "\n",
        "\n",
        "def target_encoding_cv(train_df: pd.DataFrame, test_df: pd.DataFrame,\n",
        "                       cols: List[str], target: str, n_splits: int = 10) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Conservative-style target encoding with KFold.\"\"\"\n",
        "    train = train_df.copy()\n",
        "    test = test_df.copy()\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    mean_features_train = {}\n",
        "    mean_features_test = {}\n",
        "    target_global = train[target].mean()\n",
        "    \n",
        "    for col in cols:\n",
        "        oof = np.zeros(len(train))\n",
        "        for tr_idx, val_idx in kf.split(train):\n",
        "            tr_fold = train.iloc[tr_idx]\n",
        "            fold_map = tr_fold.groupby(col)[target].mean()\n",
        "            oof[val_idx] = train[col].iloc[val_idx].map(fold_map).fillna(target_global)\n",
        "        mean_features_train[f\"mean_{col}\"] = oof\n",
        "        global_map = train.groupby(col)[target].mean()\n",
        "        mean_features_test[f\"mean_{col}\"] = test[col].map(global_map).fillna(target_global)\n",
        "    \n",
        "    train = pd.concat([train, pd.DataFrame(mean_features_train)], axis=1)\n",
        "    test = pd.concat([test, pd.DataFrame(mean_features_test)], axis=1)\n",
        "    return train, test\n",
        "\n",
        "\n",
        "def create_frequency_binning(df: pd.DataFrame, df_test: pd.DataFrame,\n",
        "                             cols: List[str], num_cols: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Conservative-style frequency encoding and quantile binning.\"\"\"\n",
        "    df = df.copy()\n",
        "    df_test = df_test.copy()\n",
        "    freq_features_train = {}\n",
        "    freq_features_test = {}\n",
        "    bin_features_train = {}\n",
        "    bin_features_test = {}\n",
        "    \n",
        "    for col in cols:\n",
        "        freq = df[col].value_counts()\n",
        "        freq_features_train[f\"{col}_freq\"] = df[col].map(freq)\n",
        "        default_value = freq.mean() if len(freq) > 0 else 0\n",
        "        freq_features_test[f\"{col}_freq\"] = df_test[col].map(freq).fillna(default_value)\n",
        "        \n",
        "        if col in num_cols:\n",
        "            for q in (5, 10, 15):\n",
        "                try:\n",
        "                    t_bins, edges = pd.qcut(df[col], q=q, labels=False, retbins=True, duplicates='drop')\n",
        "                    bin_features_train[f\"{col}_bin{q}\"] = t_bins\n",
        "                    bin_features_test[f\"{col}_bin{q}\"] = pd.cut(df_test[col], bins=edges, labels=False, include_lowest=True)\n",
        "                except:\n",
        "                    bin_features_train[f\"{col}_bin{q}\"] = pd.Series(0, index=df.index)\n",
        "                    bin_features_test[f\"{col}_bin{q}\"] = pd.Series(0, index=df_test.index)\n",
        "    \n",
        "    df = pd.concat([df, pd.DataFrame(freq_features_train), pd.DataFrame(bin_features_train)], axis=1)\n",
        "    df_test = pd.concat([df_test, pd.DataFrame(freq_features_test), pd.DataFrame(bin_features_test)], axis=1)\n",
        "    return df, df_test\n",
        "\n",
        "print(\"Feature engineering functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_original_model(original: pd.DataFrame) -> Tuple[LGBMClassifier, List[str]]:\n",
        "    \"\"\"Train model on original dataset for residual boosting.\"\"\"\n",
        "    print(\"\\n=== Training Original Dataset Model (Residual Booster) ===\")\n",
        "    df = original.copy()\n",
        "    grade_map = create_grade_mapping()\n",
        "    df['grade_enc'] = df['grade_subgrade'].map(grade_map)\n",
        "    cat_cols = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose']\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        df[f'{col}_le'] = le.fit_transform(df[col].astype(str))\n",
        "    eps = 1e-6\n",
        "    df['loan_to_income'] = df['loan_amount'] / (df['annual_income'] + eps)\n",
        "    df['monthly_income'] = df['annual_income'] / 12\n",
        "    df['credit_score_to_loan'] = df['credit_score'] / (df['loan_amount'] + eps)\n",
        "    feature_cols = ['annual_income', 'debt_to_income_ratio', 'credit_score',\n",
        "                    'loan_amount', 'interest_rate', 'grade_enc',\n",
        "                    'loan_to_income', 'monthly_income', 'credit_score_to_loan'] + \\\n",
        "                   [f'{col}_le' for col in cat_cols]\n",
        "    X_orig = df[feature_cols]\n",
        "    y_orig = df['loan_paid_back'].values\n",
        "    model = LGBMClassifier(n_estimators=1000, learning_rate=0.05, num_leaves=31,\n",
        "                          subsample=0.8, colsample_bytree=0.8, objective='binary',\n",
        "                          metric='auc', n_jobs=-1, random_state=RANDOM_STATE, verbose=-1)\n",
        "    model.fit(X_orig, y_orig)\n",
        "    score = roc_auc_score(y_orig, model.predict_proba(X_orig)[:, 1])\n",
        "    print(f\"  Original model AUC: {score:.5f}\")\n",
        "    return model, feature_cols\n",
        "\n",
        "\n",
        "def predict_with_original_model(model, feature_cols: List[str], df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"Use original model to predict.\"\"\"\n",
        "    data = df.copy()\n",
        "    grade_map = create_grade_mapping()\n",
        "    data['grade_enc'] = data['grade_subgrade'].map(grade_map)\n",
        "    cat_cols = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose']\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        data[f'{col}_le'] = le.fit_transform(data[col].astype(str))\n",
        "    eps = 1e-6\n",
        "    data['loan_to_income'] = data['loan_amount'] / (data['annual_income'] + eps)\n",
        "    data['monthly_income'] = data['annual_income'] / 12\n",
        "    data['credit_score_to_loan'] = data['credit_score'] / (data['loan_amount'] + eps)\n",
        "    return model.predict_proba(data[feature_cols])[:, 1]\n",
        "\n",
        "\n",
        "def comprehensive_feature_engineering(train: pd.DataFrame, test: pd.DataFrame,\n",
        "                                      target_col: str = 'loan_paid_back',\n",
        "                                      original_model=None, orig_features=None) -> Tuple[pd.DataFrame, np.ndarray, pd.DataFrame]:\n",
        "    \"\"\"Combines Conservative + Ultimate feature engineering + Residual boosting.\"\"\"\n",
        "    print(\"\\n=== Comprehensive Feature Engineering ===\")\n",
        "    y = train[target_col].values\n",
        "    train = train.copy()\n",
        "    test = test.copy()\n",
        "    \n",
        "    # Add residual features if original model available\n",
        "    if original_model is not None:\n",
        "        print(\"Adding residual boosting features...\")\n",
        "        orig_preds_train = predict_with_original_model(original_model, orig_features, train)\n",
        "        orig_preds_test = predict_with_original_model(original_model, orig_features, test)\n",
        "        train['orig_pred'] = orig_preds_train\n",
        "        test['orig_pred'] = orig_preds_test\n",
        "        print(f\"  Added orig_pred feature (range: [{orig_preds_train.min():.4f}, {orig_preds_train.max():.4f}])\")\n",
        "    \n",
        "    # Combine for consistent processing\n",
        "    train['is_train'] = 1\n",
        "    test['is_train'] = 0\n",
        "    test[target_col] = np.nan\n",
        "    full_df = pd.concat([train, test], axis=0, ignore_index=True)\n",
        "    \n",
        "    # Extract grade/subgrade (Conservative style)\n",
        "    full_df[\"subgrade\"] = full_df[\"grade_subgrade\"].str[1:].astype(int)\n",
        "    full_df[\"grade\"] = full_df[\"grade_subgrade\"].str[0]\n",
        "    \n",
        "    # Grade encoding (Ultimate style)\n",
        "    grade_map = create_grade_mapping()\n",
        "    full_df['grade_enc'] = full_df['grade_subgrade'].map(grade_map)\n",
        "    full_df['grade_letter_enc'] = full_df['grade'].map({l: i for i, l in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G'])})\n",
        "    full_df['grade_number'] = full_df['grade_subgrade'].str[1].astype(int)\n",
        "    \n",
        "    # Financial ratios (Ultimate style)\n",
        "    eps = 1e-6\n",
        "    full_df['loan_to_income'] = full_df['loan_amount'] / (full_df['annual_income'] + eps)\n",
        "    full_df['monthly_income'] = full_df['annual_income'] / 12\n",
        "    full_df['monthly_debt'] = full_df['monthly_income'] * full_df['debt_to_income_ratio']\n",
        "    full_df['disposable_income'] = full_df['monthly_income'] - full_df['monthly_debt']\n",
        "    full_df['interest_amount'] = full_df['loan_amount'] * (full_df['interest_rate'] / 100)\n",
        "    full_df['total_payment'] = full_df['loan_amount'] + full_df['interest_amount']\n",
        "    full_df['payment_to_income'] = full_df['total_payment'] / (full_df['annual_income'] + eps)\n",
        "    full_df['credit_score_to_loan'] = full_df['credit_score'] / (full_df['loan_amount'] + eps)\n",
        "    full_df['credit_score_to_income'] = full_df['credit_score'] / (full_df['annual_income'] + eps)\n",
        "    full_df['interest_burden'] = full_df['interest_rate'] * full_df['loan_to_income']\n",
        "    \n",
        "    # Log transforms\n",
        "    for col in ['annual_income', 'loan_amount', 'monthly_income', 'total_payment']:\n",
        "        full_df[f'log_{col}'] = np.log1p(full_df[col])\n",
        "    \n",
        "    # Label encoding\n",
        "    cat_cols = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose']\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        full_df[f'{col}_le'] = le.fit_transform(full_df[col].astype(str))\n",
        "    \n",
        "    # Split back for target encoding\n",
        "    train_proc = full_df[full_df['is_train'] == 1].copy()\n",
        "    test_proc = full_df[full_df['is_train'] == 0].copy()\n",
        "    train_proc[target_col] = y\n",
        "    \n",
        "    # Conservative-style target encoding\n",
        "    print(\"Applying target encoding...\")\n",
        "    cols_for_te = train_proc.drop(columns=[target_col, 'is_train', 'id'], errors='ignore').columns.tolist()\n",
        "    train_proc, test_proc = target_encoding_cv(train_proc, test_proc, cols_for_te, target_col, n_splits=10)\n",
        "    \n",
        "    # Conservative-style frequency + binning\n",
        "    print(\"Creating frequency and binning features...\")\n",
        "    num_cols = [c for c in cols_for_te if train_proc[c].dtype not in ('object', 'category', 'bool')]\n",
        "    train_proc, test_proc = create_frequency_binning(train_proc, test_proc, cols_for_te, num_cols)\n",
        "    \n",
        "    # Ultimate-style interactions\n",
        "    full_df_merged = pd.concat([train_proc, test_proc], axis=0, ignore_index=True)\n",
        "    full_df_merged['credit_dti_interaction'] = full_df_merged['credit_score'] * full_df_merged['debt_to_income_ratio']\n",
        "    full_df_merged['income_credit_interaction'] = full_df_merged['log_annual_income'] * full_df_merged['credit_score']\n",
        "    full_df_merged['loan_interest_interaction'] = full_df_merged['loan_amount'] * full_df_merged['interest_rate']\n",
        "    full_df_merged['grade_loan_interaction'] = full_df_merged['grade_enc'] * full_df_merged['loan_amount']\n",
        "    \n",
        "    # Binned features\n",
        "    full_df_merged['credit_score_bin'] = pd.cut(full_df_merged['credit_score'], bins=10, labels=False)\n",
        "    full_df_merged['income_bin'] = pd.cut(full_df_merged['annual_income'], bins=10, labels=False)\n",
        "    full_df_merged['interest_rate_bin'] = pd.cut(full_df_merged['interest_rate'], bins=10, labels=False)\n",
        "    \n",
        "    # Risk indicators\n",
        "    full_df_merged['high_dti'] = (full_df_merged['debt_to_income_ratio'] > 0.4).astype(int)\n",
        "    full_df_merged['low_credit'] = (full_df_merged['credit_score'] < 600).astype(int)\n",
        "    full_df_merged['high_interest'] = (full_df_merged['interest_rate'] > 15).astype(int)\n",
        "    full_df_merged['risk_flags'] = full_df_merged['high_dti'] + full_df_merged['low_credit'] + full_df_merged['high_interest']\n",
        "    \n",
        "    # Split back\n",
        "    train_final = full_df_merged[full_df_merged['is_train'] == 1].copy()\n",
        "    test_final = full_df_merged[full_df_merged['is_train'] == 0].copy()\n",
        "    \n",
        "    # Drop unwanted columns\n",
        "    drop_cols = ['id', 'is_train', target_col, 'grade'] + cat_cols + ['grade_subgrade']\n",
        "    drop_cols = [c for c in drop_cols if c in train_final.columns]\n",
        "    \n",
        "    # Conservative feature removal\n",
        "    remove = [\n",
        "        \"education_level\", \"loan_purpose\", \"grade_subgrade\",\n",
        "        \"interest_rate\", \"marital_status\", \"gender\",\n",
        "        \"employment_status_freq\", \"credit_score_bin5\",\n",
        "        \"loan_amount_bin5\", \"credit_score_freq\",\n",
        "        \"mean_subgrade\", \"subgrade_bin15\", \"subgrade_bin10\",\n",
        "        \"debt_to_income_ratio_bin5\"\n",
        "    ]\n",
        "    drop_cols.extend([c for c in remove if c in train_final.columns])\n",
        "    \n",
        "    X = train_final.drop(columns=drop_cols)\n",
        "    X_test = test_final.drop(columns=[c for c in drop_cols if c in test_final.columns])\n",
        "    \n",
        "    # Convert categoricals\n",
        "    cat_cols_final = [c for c in X.columns if X[c].dtype == 'object']\n",
        "    for col in cat_cols_final:\n",
        "        X[col] = X[col].astype('category')\n",
        "        X_test[col] = X_test[col].astype('category')\n",
        "    \n",
        "    print(f\"Final feature count: {X.shape[1]}\")\n",
        "    return X, y, X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train original model if available (for residual boosting)\n",
        "original_model = None\n",
        "orig_features = None\n",
        "if has_original:\n",
        "    original_model, orig_features = train_original_model(original)\n",
        "    print(\"âœ“ Original model trained - residual boosting enabled!\")\n",
        "\n",
        "# Apply comprehensive feature engineering\n",
        "X, y, X_test = comprehensive_feature_engineering(train, test, \n",
        "                                                  original_model=original_model,\n",
        "                                                  orig_features=orig_features)\n",
        "print(f\"\\nâœ“ Feature engineering complete!\")\n",
        "print(f\"Training features: {X.shape}\")\n",
        "print(f\"Test features: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_cv(X: pd.DataFrame, y: np.ndarray, X_test: pd.DataFrame,\n",
        "                   model_type: str, params: dict, n_folds: int = 10) -> Tuple[np.ndarray, np.ndarray, float]:\n",
        "    \"\"\"Train model with cross-validation.\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "    oof_preds = np.zeros(len(X))\n",
        "    test_preds = np.zeros(len(X_test))\n",
        "    \n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
        "        X_train, y_train = X.iloc[train_idx], y[train_idx]\n",
        "        X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
        "        \n",
        "        if model_type == 'lgb':\n",
        "            model = LGBMClassifier(**params)\n",
        "            try:\n",
        "                from lightgbm import early_stopping\n",
        "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
        "                         eval_metric='auc', callbacks=[early_stopping(200, verbose=False)])\n",
        "            except:\n",
        "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='auc')\n",
        "        elif model_type == 'xgb':\n",
        "            model = xgb.XGBClassifier(**params)\n",
        "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
        "        elif model_type == 'cat':\n",
        "            model = CatBoostClassifier(**params)\n",
        "            model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=200, verbose=False)\n",
        "        \n",
        "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
        "        test_preds += model.predict_proba(X_test)[:, 1] / n_folds\n",
        "        \n",
        "        score = roc_auc_score(y_val, oof_preds[val_idx])\n",
        "        if fold % 2 == 0 or fold == n_folds:\n",
        "            print(f\"  Fold {fold}/{n_folds}: AUC = {score:.5f}\")\n",
        "    \n",
        "    overall_score = roc_auc_score(y, oof_preds)\n",
        "    return oof_preds, test_preds, overall_score\n",
        "\n",
        "print(\"Model training function defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train multiple diverse models\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING MULTIPLE MODELS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_oof = []\n",
        "all_preds = []\n",
        "model_names = []\n",
        "\n",
        "# Model 1: Conservative LightGBM\n",
        "print(\"\\n[1/5] Training Conservative LightGBM...\")\n",
        "lgb_conservative_params = {\n",
        "    'n_estimators': 5000, 'learning_rate': 0.03, 'num_leaves': 80,\n",
        "    'max_depth': 6, 'min_child_samples': 20, 'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8, 'reg_alpha': 0.2, 'reg_lambda': 0.4,\n",
        "    'min_data_in_leaf': 40, 'objective': 'binary', 'metric': 'auc',\n",
        "    'n_jobs': -1, 'device': 'cpu', 'random_state': RANDOM_STATE, 'verbose': -1\n",
        "}\n",
        "oof_lgb_cons, pred_lgb_cons, score_lgb_cons = train_model_cv(X, y, X_test, 'lgb', lgb_conservative_params, N_FOLDS)\n",
        "all_oof.append(oof_lgb_cons)\n",
        "all_preds.append(pred_lgb_cons)\n",
        "model_names.append('LGB_Conservative')\n",
        "print(f\"  OOF Score: {score_lgb_cons:.5f}\")\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 2: Aggressive LightGBM\n",
        "print(\"\\n[2/5] Training Aggressive LightGBM...\")\n",
        "lgb_aggressive_params = {\n",
        "    'n_estimators': 5000, 'learning_rate': 0.01, 'num_leaves': 127,\n",
        "    'max_depth': 8, 'min_child_samples': 10, 'subsample': 0.75,\n",
        "    'colsample_bytree': 0.6, 'reg_alpha': 0.1, 'reg_lambda': 1.0,\n",
        "    'objective': 'binary', 'metric': 'auc', 'n_jobs': -1,\n",
        "    'device': 'cpu', 'random_state': RANDOM_STATE + 1, 'verbose': -1\n",
        "}\n",
        "oof_lgb_agg, pred_lgb_agg, score_lgb_agg = train_model_cv(X, y, X_test, 'lgb', lgb_aggressive_params, N_FOLDS)\n",
        "all_oof.append(oof_lgb_agg)\n",
        "all_preds.append(pred_lgb_agg)\n",
        "model_names.append('LGB_Aggressive')\n",
        "print(f\"  OOF Score: {score_lgb_agg:.5f}\")\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 3: XGBoost\n",
        "print(\"\\n[3/5] Training XGBoost...\")\n",
        "xgb_params = {\n",
        "    'n_estimators': 5000, 'learning_rate': 0.01, 'max_depth': 7,\n",
        "    'min_child_weight': 3, 'subsample': 0.75, 'colsample_bytree': 0.6,\n",
        "    'reg_alpha': 0.1, 'reg_lambda': 1.0, 'objective': 'binary:logistic',\n",
        "    'n_jobs': -1, 'tree_method': 'hist', 'random_state': RANDOM_STATE, 'eval_metric': 'auc'\n",
        "}\n",
        "oof_xgb, pred_xgb, score_xgb = train_model_cv(X, y, X_test, 'xgb', xgb_params, N_FOLDS)\n",
        "all_oof.append(oof_xgb)\n",
        "all_preds.append(pred_xgb)\n",
        "model_names.append('XGB')\n",
        "print(f\"  OOF Score: {score_xgb:.5f}\")\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 4: CatBoost\n",
        "print(\"\\n[4/5] Training CatBoost...\")\n",
        "cat_params = {\n",
        "    'iterations': 5000, 'learning_rate': 0.01, 'depth': 7,\n",
        "    'l2_leaf_reg': 3, 'min_data_in_leaf': 20, 'rsm': 0.6,\n",
        "    'subsample': 0.75, 'loss_function': 'Logloss', 'eval_metric': 'AUC',\n",
        "    'verbose': False, 'random_seed': RANDOM_STATE, 'allow_writing_files': False\n",
        "}\n",
        "oof_cat, pred_cat, score_cat = train_model_cv(X, y, X_test, 'cat', cat_params, N_FOLDS)\n",
        "all_oof.append(oof_cat)\n",
        "all_preds.append(pred_cat)\n",
        "model_names.append('CatBoost')\n",
        "print(f\"  OOF Score: {score_cat:.5f}\")\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 5: Balanced LightGBM (medium complexity)\n",
        "print(\"\\n[5/5] Training Balanced LightGBM...\")\n",
        "lgb_balanced_params = {\n",
        "    'n_estimators': 5000, 'learning_rate': 0.015, 'num_leaves': 63,\n",
        "    'max_depth': 7, 'min_child_samples': 15, 'subsample': 0.8,\n",
        "    'colsample_bytree': 0.7, 'reg_alpha': 0.15, 'reg_lambda': 0.5,\n",
        "    'objective': 'binary', 'metric': 'auc', 'n_jobs': -1,\n",
        "    'device': 'cpu', 'random_state': RANDOM_STATE + 2, 'verbose': -1\n",
        "}\n",
        "oof_lgb_bal, pred_lgb_bal, score_lgb_bal = train_model_cv(X, y, X_test, 'lgb', lgb_balanced_params, N_FOLDS)\n",
        "all_oof.append(oof_lgb_bal)\n",
        "all_preds.append(pred_lgb_bal)\n",
        "model_names.append('LGB_Balanced')\n",
        "print(f\"  OOF Score: {score_lgb_bal:.5f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL TRAINING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "for name, oof in zip(model_names, all_oof):\n",
        "    print(f\"{name}: {roc_auc_score(y, oof):.5f}\")\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_optimal_weights(oof_list: List[np.ndarray], y: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Find optimal ensemble weights using simplified grid search.\"\"\"\n",
        "    print(\"\\n=== Finding Optimal Blend Weights ===\")\n",
        "    best_score = -1\n",
        "    best_weights = None\n",
        "    n_models = len(oof_list)\n",
        "    \n",
        "    # Simplified grid search (faster)\n",
        "    if n_models == 5:\n",
        "        # Test common weight combinations\n",
        "        test_weights = [\n",
        "            [0.2, 0.2, 0.2, 0.2, 0.2],  # Equal\n",
        "            [0.3, 0.25, 0.2, 0.15, 0.1],  # Favor first\n",
        "            [0.25, 0.25, 0.2, 0.15, 0.15],\n",
        "            [0.3, 0.2, 0.2, 0.15, 0.15],\n",
        "            [0.2, 0.3, 0.2, 0.15, 0.15],\n",
        "            [0.15, 0.25, 0.25, 0.2, 0.15],\n",
        "        ]\n",
        "    else:\n",
        "        # Generic approach\n",
        "        test_weights = [[1/n_models] * n_models]\n",
        "        for i in range(n_models):\n",
        "            w = [0.1] * n_models\n",
        "            w[i] = 0.9 - 0.1 * (n_models - 1)\n",
        "            test_weights.append(w)\n",
        "    \n",
        "    # Test each weight combination\n",
        "    for weights in test_weights:\n",
        "        weights = np.array(weights)\n",
        "        weights = weights / weights.sum()  # Normalize\n",
        "        blended = sum(w * oof for w, oof in zip(weights, oof_list))\n",
        "        score = roc_auc_score(y, blended)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_weights = weights.copy()\n",
        "    \n",
        "    print(f\"Best weights: {dict(zip(model_names, best_weights))}\")\n",
        "    print(f\"Best blended OOF: {best_score:.5f}\")\n",
        "    return best_weights\n",
        "\n",
        "# Find optimal weights\n",
        "optimal_weights = find_optimal_weights(all_oof, y)\n",
        "\n",
        "# Create weighted blend\n",
        "final_pred = sum(w * p for w, p in zip(optimal_weights, all_preds))\n",
        "final_oof = sum(w * o for w, o in zip(optimal_weights, all_oof))\n",
        "final_score = roc_auc_score(y, final_oof)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"FINAL BLENDED OOF SCORE: {final_score:.5f}\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced blending techniques\n",
        "print(\"\\n=== Applying Advanced Blending ===\")\n",
        "\n",
        "# Power averaging (favors confident predictions) - for test predictions\n",
        "power_avg = np.power(np.power(np.array(all_preds).T, 2).mean(axis=1), 1/2)\n",
        "\n",
        "# Rank averaging (robust to outliers) - for test predictions\n",
        "rank_preds = np.array([np.argsort(np.argsort(p)) / len(p) for p in all_preds]).T\n",
        "rank_avg = rank_preds.mean(axis=1)\n",
        "\n",
        "# Geometric mean - for test predictions\n",
        "geometric_mean = np.power(np.prod(np.array(all_preds).T, axis=1), 1/len(all_preds))\n",
        "\n",
        "# Test different blends (test predictions)\n",
        "blends_test = {\n",
        "    'weighted': final_pred,\n",
        "    'power_avg': power_avg,\n",
        "    'rank_avg': rank_avg,\n",
        "    'geometric': geometric_mean,\n",
        "    'simple_avg': np.array(all_preds).mean(axis=0)\n",
        "}\n",
        "\n",
        "# Create OOF versions for evaluation\n",
        "power_avg_oof = np.power(np.power(np.array(all_oof).T, 2).mean(axis=1), 1/2)\n",
        "rank_preds_oof = np.array([np.argsort(np.argsort(o)) / len(o) for o in all_oof]).T\n",
        "rank_avg_oof = rank_preds_oof.mean(axis=1)\n",
        "geometric_mean_oof = np.power(np.prod(np.array(all_oof).T, axis=1), 1/len(all_oof))\n",
        "\n",
        "blends_oof = {\n",
        "    'weighted': final_oof,\n",
        "    'power_avg': power_avg_oof,\n",
        "    'rank_avg': rank_avg_oof,\n",
        "    'geometric': geometric_mean_oof,\n",
        "    'simple_avg': np.array(all_oof).mean(axis=0)\n",
        "}\n",
        "\n",
        "# Evaluate on OOF\n",
        "print(\"\\nBlend comparison (OOF):\")\n",
        "best_blend_score = -1\n",
        "best_blend_name = 'weighted'\n",
        "for name in blends_oof.keys():\n",
        "    score = roc_auc_score(y, blends_oof[name])\n",
        "    print(f\"  {name:15s}: {score:.5f}\")\n",
        "    if score > best_blend_score:\n",
        "        best_blend_score = score\n",
        "        best_blend_name = name\n",
        "\n",
        "# Use best blend\n",
        "best_pred = blends_test[best_blend_name]\n",
        "print(f\"\\nâœ“ Using {best_blend_name} blend (OOF: {best_blend_score:.5f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create final submission\n",
        "submission['loan_paid_back'] = np.clip(best_pred, 0, 1)\n",
        "submission.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "# Calculate weighted score for submission selection (as suggested by competition creators)\n",
        "# This helps you choose which submission to use as final\n",
        "train_size = len(y)\n",
        "public_lb_size = 254569  # Public LB test set size (approximately)\n",
        "total_size = train_size + public_lb_size\n",
        "weight = public_lb_size / total_size\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SUBMISSION SELECTION GUIDE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Train data size: {train_size:,}\")\n",
        "print(f\"Public LB size: ~{public_lb_size:,}\")\n",
        "print(f\"Weight for public LB: {weight:.4f}\")\n",
        "print(f\"\\nWeighted Score Formula:\")\n",
        "print(f\"  Weighted Score = (1 - {weight:.4f}) Ã— CV_Score + {weight:.4f} Ã— Public_LB_Score\")\n",
        "print(f\"\\nYour CV Score: {best_blend_score:.5f}\")\n",
        "print(f\"If your Public LB Score is 0.92755:\")\n",
        "weighted_score = (1 - weight) * best_blend_score + weight * 0.92755\n",
        "print(f\"  Weighted Score = {weighted_score:.5f}\")\n",
        "print(f\"\\nðŸ’¡ Tip: Use this weighted score to compare different submissions!\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Save all predictions for analysis\n",
        "pred_df = pd.DataFrame({\n",
        "    'id': test['id'].values,\n",
        "    **{name: pred for name, pred in zip(model_names, all_preds)},\n",
        "    'weighted_blend': final_pred,\n",
        "    'power_avg': power_avg,\n",
        "    'rank_avg': rank_avg,\n",
        "    'geometric_mean': geometric_mean,\n",
        "    'final': best_pred\n",
        "})\n",
        "pred_df.to_csv(PRED_DUMP, index=False)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SUBMISSION CREATED\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"âœ“ Saved to: {OUTPUT_PATH}\")\n",
        "print(f\"âœ“ Predictions dump: {PRED_DUMP}\")\n",
        "print(f\"\\nBest Blend: {best_blend_name}\")\n",
        "print(f\"Best Blend OOF Score: {best_blend_score:.5f}\")\n",
        "print(f\"Weighted Blend OOF Score: {final_score:.5f}\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
